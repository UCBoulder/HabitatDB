import { DocumentClientTypes } from '@typedorm/document-client';
import { EntityTarget } from '@typedorm/common';
import { Connection } from '../connection/connection';
import { FilterOptions } from '../expression/filter-options-type';
import { ProjectionKeys } from '../expression/projection-keys-options-type';
import { MetadataOptions } from '../transformer/base-transformer';
interface ScanManageBaseOptions<Entity, PartitionKey> {
    /**
     * Index to scan for items
     * @default - main table
     */
    scanIndex?: string;
    /**
     * Max number of records to query
     * @default - implicit dynamo db query limit is applied
     */
    limit?: number;
    /**
     * Cursor to traverse from
     * @default none
     */
    cursor?: DocumentClientTypes.Key;
    /**
     * Specify filter to apply
     * Avoid using this where possible, since filters in dynamodb applies after items
     * are read
     * @default none
     */
    where?: FilterOptions<Entity, PartitionKey>;
    /**
     * Specifies which attributes to fetch
     * @default all attributes are fetched
     */
    select?: ProjectionKeys<Entity>;
}
export interface ScanManagerFindOptions<Entity> extends ScanManageBaseOptions<Entity, {}> {
    /**
     * Total number of segments to divide this scan in.
     *
     * @default none - all items are scanned sequentially
     */
    totalSegments?: number;
    /**
     * Limit to apply per segment.
     *
     * when no `totalSegments` is provided, this option is ignored
     * @default none - limit to apply per segment
     */
    limitPerSegment?: number;
    /**
     * Item cursor, used for paginating a scan.
     *
     * When the `totalSegments` option is provided, this option should be of type {[segmentNo]: [Key]}
     * @default none
     */
    cursor?: Record<number, ScanManageBaseOptions<Entity, {}>['cursor']> | ScanManageBaseOptions<Entity, {}>['cursor'];
    /**
     * Max number of requests to run in parallel
     *
     * When requesting parallel scan on x segments, request are executed in parallel using Promise.all
     * While it is okay to run small number of requests in parallel, it is often a good idea to enforce a concurrency controller to stop node from eating up the all the memory
     *
     * This parameter does exactly that. i.e if requested to run scan with `20,000` segments, and `requestsConcurrencyLimit` is set to `100`
     * TypeDORM will make sure that there are always only `100` requests are running in parallel at any time until all `20,000` segments have finished processing.
     *
     * @default PARALLEL_SCAN_CONCURRENCY_LIMIT
     */
    requestsConcurrencyLimit?: number;
}
export type ScanManagerCountOptions<Entity> = Pick<ScanManageBaseOptions<Entity, {}>, 'scanIndex' | 'where'>;
export interface ScanManagerParallelScanOptions extends ScanManageBaseOptions<any, any> {
    /**
     * Total number of segments to divide this scan in
     */
    totalSegments: number;
    /**
     * Limit to apply per segment
     *
     * @default none - limit to apply per segment
     */
    limitPerSegment?: number;
    /**
     * Entity to run scan for.
     *
     * When one is provided, filter expression in auto updated to include a default filer condition for matching entity
     *
     * @default none
     */
    entity?: EntityTarget<any>;
    /**
     * Per segment cursor, where key is the segment number, and value is the cursor options for that segment
     *
     * @default none
     */
    cursor?: Record<number, ScanManagerScanOptions['cursor']>;
    /**
     * Max number of requests to run in parallel
     *
     * When requesting parallel scan on x segments, request are executed in parallel using Promise.all
     * While it is okay to run small number of requests in parallel, it is often a good idea to enforce a concurrency controller to stop node from eating up the all the memory
     *
     * This parameter does exactly that. i.e if requested to run scan with `20,000` segments, and `requestsConcurrencyLimit` is set to `100`
     * TypeDORM will make sure that there are always only `100` requests are running in parallel at any time until all `20,000` segments have finished processing.
     *
     * @default PARALLEL_SCAN_CONCURRENCY_LIMIT
     */
    requestsConcurrencyLimit?: number;
}
export interface ScanManagerScanOptions extends ScanManageBaseOptions<any, any> {
    /**
     * Entity to scan
     *
     * When one is provided, filter expression in auto updated to include filer condition for this entity
     *
     * @default none
     */
    entity?: EntityTarget<any>;
    /**
     * Number of current segment
     *
     * @default none - scan is not segmented
     */
    segment?: number;
    /**
     * Total number of segments to divide this scan in
     *
     * @default none - all items are scanned sequentially
     */
    totalSegments?: number;
    /**
     * Limit to apply per segment
     *
     * @default none - limit to apply per segment
     */
    limitPerSegment?: number;
}
export declare class ScanManager {
    private connection;
    private itemsFetchedSoFarTotalParallelCount;
    private limit;
    private _dcScanTransformer;
    constructor(connection: Connection);
    /**
     * Finds all the matching entity over document client scan operation
     * @param entityClass Entity to find
     * @param findOptions find query options
     * @param metadataOptions Other metadata options
     */
    find<Entity>(entityClass: EntityTarget<Entity>, findOptions?: ScanManagerFindOptions<Entity>, metadataOptions?: MetadataOptions): Promise<{
        items: Entity[] | undefined;
        cursor: DocumentClientTypes.Key | Record<number, DocumentClientTypes.Key> | undefined;
    }>;
    /**
     * Returns total count of all matching items for current entity
     * @param entityClass Entity to count
     * @param scanOptions Extra scan options
     * @param metadataOptions Other metadata options
     */
    count<Entity>(entityClass: EntityTarget<Entity>, scanOptions?: ScanManagerCountOptions<Entity>, metadataOptions?: MetadataOptions): Promise<number>;
    /**
     * Scans all items from dynamo table in parallel while also respecting the max provisioned concurrency
     * @param scanOptions Options for parallel scan
     * @param metadataOptions Additional metadata options
     */
    parallelScan<Entity>(scanOptions: ScanManagerParallelScanOptions, metadataOptions?: MetadataOptions): Promise<{
        items: Entity[] | undefined;
        unknownItems: DocumentClientTypes.AttributeMap[] | undefined;
        cursor: Record<number, DocumentClientTypes.Key | undefined>;
    }>;
    /**
     * Low level scan operation.
     *
     * Perhaps you are looking for higher level ScanManager.find or ScanManager.parallelScan operation
     * @param scanOptions scan options to run scan with
     * @param metadataOptions any other metadata options
     */
    scan<Entity>(scanOptions?: ScanManagerScanOptions, metadataOptions?: MetadataOptions): Promise<{
        items: Entity[] | undefined;
        unknownItems: DocumentClientTypes.AttributeMap[] | undefined;
        cursor: DocumentClientTypes.Key | undefined;
    }>;
    /**
     * Recursively scans table with given options
     */
    private _internalRecursiveScan;
    /**
     * Recursively counts items form table with given options
     */
    private _internalRecursiveCount;
    /**
     * Simple wrapper to limit number of concurrent calls
     * @param promise wraps promise in a limited factory
     * @returns
     */
    private toLimited;
}
export {};
